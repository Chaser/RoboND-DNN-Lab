{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TensorFlow Deep Neural Network Lab</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this lab, you'll use all the tools you learned from the *Deep Neural Networks* lesson to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in differents font.\n",
    "\n",
    "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. While there is no predefined goal for this lab, we would like you to experiment and discuss with fellow students on what can improve such models to achieve the highest possible accuracy values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/210001 [00:00<?, ?files/s]\u001b[A\n",
      "  0%|          | 164/210001 [00:00<02:08, 1635.61files/s]\u001b[A\n",
      "  0%|          | 312/210001 [00:00<02:12, 1578.76files/s]\u001b[A\n",
      "  0%|          | 403/210001 [00:00<02:42, 1290.69files/s]\u001b[A\n",
      "  0%|          | 523/210001 [00:00<02:46, 1260.07files/s]\u001b[A\n",
      "  0%|          | 617/210001 [00:00<03:06, 1120.04files/s]\u001b[A\n",
      "  0%|          | 776/210001 [00:00<02:50, 1228.39files/s]\u001b[A\n",
      "  0%|          | 1036/210001 [00:00<02:23, 1458.16files/s]\u001b[A\n",
      "  1%|          | 1192/210001 [00:00<02:30, 1390.55files/s]\u001b[A\n",
      "  1%|          | 1339/210001 [00:00<02:31, 1375.75files/s]\u001b[A\n",
      "  1%|          | 1483/210001 [00:01<02:34, 1350.96files/s]\u001b[A\n",
      "  1%|          | 1623/210001 [00:01<02:37, 1319.54files/s]\u001b[A\n",
      "  1%|          | 1962/210001 [00:01<02:08, 1615.25files/s]\u001b[A\n",
      "  1%|          | 2346/210001 [00:01<01:46, 1954.56files/s]\u001b[A\n",
      "  1%|▏         | 2701/210001 [00:01<01:31, 2258.95files/s]\u001b[A\n",
      "  1%|▏         | 2984/210001 [00:01<01:40, 2061.12files/s]\u001b[A\n",
      "  2%|▏         | 3234/210001 [00:01<02:00, 1712.20files/s]\u001b[A\n",
      "  2%|▏         | 3446/210001 [00:01<01:57, 1764.03files/s]\u001b[A\n",
      "  2%|▏         | 3651/210001 [00:02<01:55, 1785.67files/s]\u001b[A\n",
      "  2%|▏         | 3850/210001 [00:02<01:53, 1820.29files/s]\u001b[A\n",
      "  2%|▏         | 4047/210001 [00:02<01:59, 1719.43files/s]\u001b[A\n",
      "  2%|▏         | 4231/210001 [00:02<02:10, 1576.07files/s]\u001b[A\n",
      "  2%|▏         | 4399/210001 [00:02<02:17, 1491.24files/s]\u001b[A\n",
      "  2%|▏         | 4564/210001 [00:02<02:13, 1533.20files/s]\u001b[A\n",
      "  2%|▏         | 4724/210001 [00:02<02:16, 1504.60files/s]\u001b[A\n",
      "  2%|▏         | 5091/210001 [00:02<01:52, 1827.02files/s]\u001b[A\n",
      "  3%|▎         | 5456/210001 [00:02<01:35, 2148.84files/s]\u001b[A\n",
      "  3%|▎         | 5865/210001 [00:03<01:21, 2505.10files/s]\u001b[A\n",
      "  3%|▎         | 6224/210001 [00:03<01:14, 2753.72files/s]\u001b[A\n",
      "  3%|▎         | 6636/210001 [00:03<01:06, 3057.41files/s]\u001b[A\n",
      "  3%|▎         | 7027/210001 [00:03<01:02, 3270.42files/s]\u001b[A\n",
      "  4%|▎         | 7389/210001 [00:03<01:08, 2976.46files/s]\u001b[A\n",
      "  4%|▎         | 7716/210001 [00:03<01:18, 2566.71files/s]\u001b[A\n",
      "  4%|▍         | 8003/210001 [00:03<01:26, 2340.22files/s]\u001b[A\n",
      "  4%|▍         | 8376/210001 [00:03<01:16, 2634.21files/s]\u001b[A\n",
      "  4%|▍         | 8747/210001 [00:04<01:09, 2884.56files/s]\u001b[A\n",
      "  4%|▍         | 9064/210001 [00:04<01:09, 2907.82files/s]\u001b[A\n",
      "  4%|▍         | 9375/210001 [00:04<01:28, 2269.83files/s]\u001b[A\n",
      "  5%|▍         | 9638/210001 [00:04<01:39, 2006.52files/s]\u001b[A\n",
      "  5%|▍         | 9869/210001 [00:04<01:39, 2004.89files/s]\u001b[A\n",
      "  5%|▍         | 10182/210001 [00:04<01:28, 2246.85files/s]\u001b[A\n",
      "  5%|▍         | 10445/210001 [00:04<01:25, 2347.37files/s]\u001b[A\n",
      "  5%|▌         | 10698/210001 [00:04<01:31, 2178.19files/s]\u001b[A\n",
      "  5%|▌         | 10932/210001 [00:05<01:37, 2034.03files/s]\u001b[A\n",
      "  5%|▌         | 11148/210001 [00:05<01:59, 1666.90files/s]\u001b[A\n",
      "  5%|▌         | 11440/210001 [00:05<01:43, 1912.61files/s]\u001b[A\n",
      "  6%|▌         | 11807/210001 [00:05<01:28, 2233.28files/s]\u001b[A\n",
      "  6%|▌         | 12190/210001 [00:05<01:17, 2551.80files/s]\u001b[A\n",
      "  6%|▌         | 12542/210001 [00:05<01:11, 2780.40files/s]\u001b[A\n",
      "  6%|▌         | 12857/210001 [00:05<01:39, 1976.96files/s]\u001b[A\n",
      "  6%|▌         | 13113/210001 [00:06<01:38, 1990.46files/s]\u001b[A\n",
      "  6%|▋         | 13439/210001 [00:06<01:27, 2253.24files/s]\u001b[A\n",
      "  7%|▋         | 13791/210001 [00:06<01:17, 2525.75files/s]\u001b[A\n",
      "  7%|▋         | 14125/210001 [00:06<01:11, 2724.56files/s]\u001b[A\n",
      "  7%|▋         | 14470/210001 [00:06<01:07, 2906.70files/s]\u001b[A\n",
      "  7%|▋         | 14787/210001 [00:06<01:28, 2206.13files/s]\u001b[A\n",
      "  7%|▋         | 15051/210001 [00:06<01:28, 2202.12files/s]\u001b[A\n",
      "  7%|▋         | 15302/210001 [00:06<01:35, 2036.56files/s]\u001b[A\n",
      "  7%|▋         | 15698/210001 [00:07<01:21, 2383.59files/s]\u001b[A\n",
      "  8%|▊         | 15987/210001 [00:07<01:17, 2514.38files/s]\u001b[A\n",
      "  8%|▊         | 16306/210001 [00:07<01:12, 2684.78files/s]\u001b[A\n",
      "  8%|▊         | 16599/210001 [00:07<01:10, 2748.98files/s]\u001b[A\n",
      "  8%|▊         | 16950/210001 [00:07<01:05, 2939.32files/s]\u001b[A\n",
      "  8%|▊         | 17292/210001 [00:07<01:02, 3067.93files/s]\u001b[A\n",
      "  8%|▊         | 17612/210001 [00:07<01:02, 3061.71files/s]\u001b[A\n",
      "  9%|▊         | 17928/210001 [00:07<01:02, 3090.52files/s]\u001b[A\n",
      "  9%|▊         | 18244/210001 [00:07<01:02, 3053.09files/s]\u001b[A\n",
      "  9%|▉         | 18570/210001 [00:07<01:01, 3112.25files/s]\u001b[A\n",
      "  9%|▉         | 18898/210001 [00:08<01:00, 3160.58files/s]\u001b[A\n",
      "  9%|▉         | 19285/210001 [00:08<00:57, 3343.07files/s]\u001b[A\n",
      "  9%|▉         | 19626/210001 [00:08<00:56, 3361.43files/s]\u001b[A\n",
      " 10%|▉         | 19966/210001 [00:08<00:58, 3244.25files/s]\u001b[A\n",
      " 10%|▉         | 20294/210001 [00:08<01:13, 2588.69files/s]\u001b[A\n",
      " 10%|▉         | 20577/210001 [00:08<01:19, 2368.19files/s]\u001b[A\n",
      " 10%|▉         | 20834/210001 [00:08<01:20, 2344.74files/s]\u001b[A\n",
      " 10%|█         | 21083/210001 [00:08<01:19, 2383.12files/s]\u001b[A\n",
      " 10%|█         | 21391/210001 [00:09<01:13, 2556.63files/s]\u001b[A\n",
      " 10%|█         | 21710/210001 [00:09<01:09, 2717.45files/s]\u001b[A\n",
      " 10%|█         | 22050/210001 [00:09<01:05, 2890.84files/s]\u001b[A\n",
      " 11%|█         | 22352/210001 [00:09<01:04, 2927.92files/s]\u001b[A\n",
      " 11%|█         | 22652/210001 [00:09<01:20, 2314.24files/s]\u001b[A\n",
      " 11%|█         | 22909/210001 [00:09<01:49, 1714.88files/s]\u001b[A\n",
      " 11%|█         | 23126/210001 [00:09<01:42, 1829.31files/s]\u001b[A\n",
      " 11%|█         | 23391/210001 [00:09<01:32, 2016.02files/s]\u001b[A\n",
      " 11%|█▏        | 23675/210001 [00:10<01:24, 2208.01files/s]\u001b[A\n",
      " 11%|█▏        | 23986/210001 [00:10<01:16, 2418.38files/s]\u001b[A\n",
      " 12%|█▏        | 24251/210001 [00:10<01:21, 2267.56files/s]\u001b[A\n",
      " 12%|█▏        | 24496/210001 [00:10<01:42, 1802.29files/s]\u001b[A\n",
      " 12%|█▏        | 24788/210001 [00:10<01:30, 2036.08files/s]\u001b[A\n",
      " 12%|█▏        | 25141/210001 [00:10<01:19, 2332.04files/s]\u001b[A\n",
      " 12%|█▏        | 25470/210001 [00:10<01:12, 2554.14files/s]\u001b[A\n",
      " 12%|█▏        | 25823/210001 [00:10<01:06, 2784.17files/s]\u001b[A\n",
      " 12%|█▏        | 26170/210001 [00:11<01:02, 2958.40files/s]\u001b[A\n",
      " 13%|█▎        | 26489/210001 [00:11<01:01, 3001.22files/s]\u001b[A\n",
      " 13%|█▎        | 26846/210001 [00:11<00:58, 3151.65files/s]\u001b[A\n",
      " 13%|█▎        | 27205/210001 [00:11<00:55, 3271.47files/s]\u001b[A\n",
      " 13%|█▎        | 27554/210001 [00:11<00:54, 3333.59files/s]\u001b[A\n",
      " 13%|█▎        | 27895/210001 [00:11<00:54, 3324.11files/s]\u001b[A\n",
      " 13%|█▎        | 28284/210001 [00:11<00:52, 3475.68files/s]\u001b[A\n",
      " 14%|█▎        | 28638/210001 [00:11<00:52, 3470.86files/s]\u001b[A\n",
      " 14%|█▍        | 28989/210001 [00:11<00:57, 3142.70files/s]\u001b[A\n",
      " 14%|█▍        | 29312/210001 [00:12<01:10, 2557.47files/s]\u001b[A\n",
      " 14%|█▍        | 29645/210001 [00:12<01:05, 2747.45files/s]\u001b[A\n",
      " 14%|█▍        | 29941/210001 [00:12<01:19, 2258.28files/s]\u001b[A\n",
      " 14%|█▍        | 30196/210001 [00:12<01:33, 1922.88files/s]\u001b[A\n",
      " 14%|█▍        | 30418/210001 [00:12<01:37, 1844.56files/s]\u001b[A\n",
      " 15%|█▍        | 30655/210001 [00:12<01:30, 1975.51files/s]\u001b[A\n",
      " 15%|█▍        | 31034/210001 [00:12<01:17, 2306.04files/s]\u001b[A\n",
      " 15%|█▍        | 31298/210001 [00:13<01:30, 1963.96files/s]\u001b[A\n",
      " 15%|█▌        | 31587/210001 [00:13<01:22, 2172.28files/s]\u001b[A\n",
      " 15%|█▌        | 31983/210001 [00:13<01:10, 2512.16files/s]\u001b[A\n",
      " 15%|█▌        | 32384/210001 [00:13<01:02, 2828.66files/s]\u001b[A\n",
      " 16%|█▌        | 32873/210001 [00:13<00:54, 3237.33files/s]\u001b[A\n",
      " 16%|█▌        | 33268/210001 [00:13<00:51, 3421.45files/s]\u001b[A\n",
      " 16%|█▌        | 33678/210001 [00:13<00:48, 3598.89files/s]\u001b[A\n",
      " 16%|█▌        | 34067/210001 [00:13<01:01, 2854.98files/s]\u001b[A\n",
      " 16%|█▋        | 34498/210001 [00:13<00:55, 3175.93files/s]\u001b[A\n",
      " 17%|█▋        | 34898/210001 [00:14<00:51, 3384.26files/s]\u001b[A\n",
      " 17%|█▋        | 35350/210001 [00:14<00:47, 3658.85files/s]\u001b[A\n",
      " 17%|█▋        | 35752/210001 [00:14<00:46, 3758.68files/s]\u001b[A\n",
      " 17%|█▋        | 36195/210001 [00:14<00:44, 3936.59files/s]\u001b[A\n",
      " 17%|█▋        | 36637/210001 [00:14<00:42, 4068.87files/s]\u001b[A\n",
      " 18%|█▊        | 37058/210001 [00:14<00:42, 4030.82files/s]\u001b[A\n",
      " 18%|█▊        | 37471/210001 [00:14<00:43, 4009.03files/s]\u001b[A\n",
      " 18%|█▊        | 37922/210001 [00:14<00:41, 4146.57files/s]\u001b[A\n",
      " 18%|█▊        | 38343/210001 [00:14<00:41, 4139.86files/s]\u001b[A\n",
      " 18%|█▊        | 38762/210001 [00:15<00:55, 3071.19files/s]\u001b[A\n",
      " 19%|█▊        | 39113/210001 [00:15<00:57, 2960.00files/s]\u001b[A\n",
      " 19%|█▉        | 39518/210001 [00:15<00:52, 3218.87files/s]\u001b[A\n",
      " 19%|█▉        | 39891/210001 [00:15<00:50, 3356.78files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 40288/210001 [00:15<00:48, 3519.75files/s]\u001b[A\n",
      " 19%|█▉        | 40658/210001 [00:15<00:53, 3177.36files/s]\u001b[A\n",
      " 20%|█▉        | 40994/210001 [00:15<01:07, 2492.73files/s]\u001b[A\n",
      " 20%|█▉        | 41279/210001 [00:15<01:16, 2196.50files/s]\u001b[A\n",
      " 20%|█▉        | 41588/210001 [00:16<01:10, 2403.14files/s]\u001b[A\n",
      " 20%|█▉        | 41934/210001 [00:16<01:03, 2644.93files/s]\u001b[A\n",
      " 20%|██        | 42351/210001 [00:16<00:56, 2969.81files/s]\u001b[A\n",
      " 20%|██        | 42770/210001 [00:16<00:51, 3252.01files/s]\u001b[A\n",
      " 21%|██        | 43156/210001 [00:16<00:48, 3411.87files/s]\u001b[A\n",
      " 21%|██        | 43571/210001 [00:16<00:46, 3603.71files/s]\u001b[A\n",
      " 21%|██        | 43951/210001 [00:16<00:45, 3613.29files/s]\u001b[A\n",
      " 21%|██        | 44349/210001 [00:16<00:44, 3714.99files/s]\u001b[A\n",
      " 21%|██▏       | 44731/210001 [00:16<00:45, 3649.07files/s]\u001b[A\n",
      " 21%|██▏       | 45104/210001 [00:17<00:50, 3245.67files/s]\u001b[A\n",
      " 22%|██▏       | 45442/210001 [00:17<01:06, 2481.69files/s]\u001b[A\n",
      " 22%|██▏       | 45727/210001 [00:17<01:19, 2064.53files/s]\u001b[A\n",
      " 22%|██▏       | 46123/210001 [00:17<01:07, 2410.30files/s]\u001b[A\n",
      " 22%|██▏       | 46471/210001 [00:17<01:01, 2654.07files/s]\u001b[A\n",
      " 22%|██▏       | 46829/210001 [00:17<00:56, 2877.31files/s]\u001b[A\n",
      " 22%|██▏       | 47152/210001 [00:17<00:55, 2943.60files/s]\u001b[A\n",
      " 23%|██▎       | 47471/210001 [00:17<00:53, 3011.63files/s]\u001b[A\n",
      " 23%|██▎       | 47875/210001 [00:18<00:49, 3259.63files/s]\u001b[A\n",
      " 23%|██▎       | 48220/210001 [00:18<00:49, 3235.77files/s]\u001b[A\n",
      " 23%|██▎       | 48557/210001 [00:18<00:50, 3226.30files/s]\u001b[A\n",
      " 23%|██▎       | 48941/210001 [00:18<00:47, 3387.90files/s]\u001b[A\n",
      " 23%|██▎       | 49332/210001 [00:18<00:45, 3529.10files/s]\u001b[A\n",
      " 24%|██▎       | 49693/210001 [00:18<00:45, 3504.31files/s]\u001b[A\n",
      " 24%|██▍       | 50049/210001 [00:18<00:48, 3303.64files/s]\u001b[A\n",
      " 24%|██▍       | 50386/210001 [00:18<00:56, 2845.06files/s]\u001b[A\n",
      " 24%|██▍       | 50686/210001 [00:19<01:12, 2198.82files/s]\u001b[A\n",
      " 24%|██▍       | 50940/210001 [00:19<01:45, 1507.92files/s]\u001b[A\n",
      " 24%|██▍       | 51144/210001 [00:19<01:43, 1527.84files/s]\u001b[A\n",
      " 25%|██▍       | 51488/210001 [00:19<01:26, 1833.33files/s]\u001b[A\n",
      " 25%|██▍       | 51836/210001 [00:19<01:14, 2135.87files/s]\u001b[A\n",
      " 25%|██▍       | 52201/210001 [00:19<01:04, 2438.88files/s]\u001b[A\n",
      " 25%|██▍       | 52499/210001 [00:19<01:01, 2577.00files/s]\u001b[A\n",
      " 25%|██▌       | 52797/210001 [00:19<00:59, 2655.53files/s]\u001b[A\n",
      " 25%|██▌       | 53092/210001 [00:20<01:03, 2456.40files/s]\u001b[A\n",
      " 25%|██▌       | 53361/210001 [00:20<01:14, 2114.65files/s]\u001b[A\n",
      " 26%|██▌       | 53597/210001 [00:20<01:18, 2001.29files/s]\u001b[A\n",
      " 26%|██▌       | 53816/210001 [00:20<01:23, 1861.72files/s]\u001b[A\n",
      " 26%|██▌       | 54017/210001 [00:20<01:32, 1684.56files/s]\u001b[A\n",
      " 26%|██▌       | 54200/210001 [00:20<01:33, 1657.73files/s]\u001b[A\n",
      " 26%|██▌       | 54453/210001 [00:20<01:24, 1847.08files/s]\u001b[A\n",
      " 26%|██▌       | 54652/210001 [00:21<01:32, 1672.29files/s]\u001b[A\n",
      " 26%|██▌       | 54853/210001 [00:21<01:28, 1754.68files/s]\u001b[A\n",
      " 26%|██▌       | 55039/210001 [00:21<01:32, 1683.64files/s]\u001b[A\n",
      " 26%|██▋       | 55215/210001 [00:21<01:43, 1488.34files/s]\u001b[A\n",
      " 26%|██▋       | 55376/210001 [00:21<01:41, 1522.38files/s]\u001b[A\n",
      " 26%|██▋       | 55536/210001 [00:21<01:42, 1500.29files/s]\u001b[A\n",
      " 27%|██▋       | 55693/210001 [00:21<01:41, 1514.77files/s]\u001b[A\n",
      " 27%|██▋       | 55848/210001 [00:21<01:46, 1444.26files/s]\u001b[A\n",
      " 27%|██▋       | 56068/210001 [00:21<01:35, 1609.57files/s]\u001b[A\n",
      " 27%|██▋       | 56304/210001 [00:22<01:26, 1778.64files/s]\u001b[A\n",
      " 27%|██▋       | 56551/210001 [00:22<01:19, 1941.33files/s]\u001b[A\n",
      " 27%|██▋       | 56831/210001 [00:22<01:11, 2135.84files/s]\u001b[A\n",
      " 27%|██▋       | 57060/210001 [00:22<01:13, 2070.18files/s]\u001b[A\n",
      " 27%|██▋       | 57278/210001 [00:22<01:17, 1979.77files/s]\u001b[A\n",
      " 27%|██▋       | 57573/210001 [00:22<01:09, 2195.90files/s]\u001b[A\n",
      " 28%|██▊       | 57853/210001 [00:22<01:04, 2347.64files/s]\u001b[A\n",
      " 28%|██▊       | 58100/210001 [00:22<01:04, 2346.92files/s]\u001b[A\n",
      " 28%|██▊       | 58344/210001 [00:22<01:05, 2307.03files/s]\u001b[A\n",
      " 28%|██▊       | 58581/210001 [00:23<01:07, 2241.88files/s]\u001b[A\n",
      " 28%|██▊       | 58810/210001 [00:23<01:15, 1999.46files/s]\u001b[A\n",
      " 28%|██▊       | 59019/210001 [00:23<01:18, 1925.54files/s]\u001b[A\n",
      " 28%|██▊       | 59253/210001 [00:23<01:14, 2032.47files/s]\u001b[A\n",
      " 28%|██▊       | 59546/210001 [00:23<01:07, 2236.52files/s]\u001b[A\n",
      " 28%|██▊       | 59781/210001 [00:23<01:11, 2091.08files/s]\u001b[A\n",
      " 29%|██▊       | 60086/210001 [00:23<01:04, 2308.60files/s]\u001b[A\n",
      " 29%|██▊       | 60334/210001 [00:23<01:03, 2356.28files/s]\u001b[A\n",
      " 29%|██▉       | 60580/210001 [00:23<01:10, 2123.32files/s]\u001b[A\n",
      " 29%|██▉       | 60804/210001 [00:24<01:19, 1865.61files/s]\u001b[A\n",
      " 29%|██▉       | 61005/210001 [00:24<01:24, 1770.45files/s]\u001b[A\n",
      " 29%|██▉       | 61193/210001 [00:24<01:34, 1579.47files/s]\u001b[A\n",
      " 29%|██▉       | 61363/210001 [00:24<01:44, 1416.67files/s]\u001b[A\n",
      " 29%|██▉       | 61562/210001 [00:24<01:35, 1549.98files/s]\u001b[A\n",
      " 29%|██▉       | 61900/210001 [00:24<01:20, 1850.25files/s]\u001b[A\n",
      " 30%|██▉       | 62227/210001 [00:24<01:09, 2126.97files/s]\u001b[A\n",
      " 30%|██▉       | 62526/210001 [00:24<01:03, 2328.46files/s]\u001b[A\n",
      " 30%|██▉       | 62792/210001 [00:25<01:02, 2341.74files/s]\u001b[A\n",
      " 30%|███       | 63049/210001 [00:25<01:07, 2165.53files/s]\u001b[A\n",
      " 30%|███       | 63284/210001 [00:25<01:15, 1933.80files/s]\u001b[A\n",
      " 30%|███       | 63516/210001 [00:25<01:11, 2034.96files/s]\u001b[A\n",
      " 30%|███       | 63744/210001 [00:25<01:09, 2101.82files/s]\u001b[A\n",
      " 30%|███       | 63965/210001 [00:25<01:12, 2026.51files/s]\u001b[A\n",
      " 31%|███       | 64191/210001 [00:25<01:09, 2090.97files/s]\u001b[A\n",
      " 31%|███       | 64450/210001 [00:25<01:05, 2218.23files/s]\u001b[A\n",
      " 31%|███       | 64727/210001 [00:25<01:01, 2357.17files/s]\u001b[A\n",
      " 31%|███       | 65065/210001 [00:26<00:55, 2592.34files/s]\u001b[A\n",
      " 31%|███       | 65337/210001 [00:26<00:56, 2572.71files/s]\u001b[A\n",
      " 31%|███▏      | 65698/210001 [00:26<00:51, 2814.84files/s]\u001b[A\n",
      " 31%|███▏      | 65993/210001 [00:26<00:51, 2808.61files/s]\u001b[A\n",
      " 32%|███▏      | 66283/210001 [00:26<01:06, 2174.65files/s]\u001b[A\n",
      " 32%|███▏      | 66529/210001 [00:26<01:11, 2001.50files/s]\u001b[A\n",
      " 32%|███▏      | 66914/210001 [00:26<01:01, 2337.88files/s]\u001b[A\n",
      " 32%|███▏      | 67293/210001 [00:26<00:54, 2641.48files/s]\u001b[A\n",
      " 32%|███▏      | 67649/210001 [00:27<00:49, 2862.30files/s]\u001b[A\n",
      " 32%|███▏      | 68015/210001 [00:27<00:46, 3061.11files/s]\u001b[A\n",
      " 33%|███▎      | 68367/210001 [00:27<00:44, 3184.30files/s]\u001b[A\n",
      " 33%|███▎      | 68706/210001 [00:27<00:47, 3000.21files/s]\u001b[A\n",
      " 33%|███▎      | 69023/210001 [00:27<01:02, 2240.79files/s]\u001b[A\n",
      " 33%|███▎      | 69367/210001 [00:27<00:56, 2502.02files/s]\u001b[A\n",
      " 33%|███▎      | 69655/210001 [00:27<01:07, 2090.39files/s]\u001b[A\n",
      " 33%|███▎      | 70051/210001 [00:27<00:57, 2434.96files/s]\u001b[A\n",
      " 33%|███▎      | 70344/210001 [00:28<00:54, 2563.71files/s]\u001b[A\n",
      " 34%|███▎      | 70657/210001 [00:28<00:51, 2707.26files/s]\u001b[A\n",
      " 34%|███▍      | 70955/210001 [00:28<00:50, 2759.86files/s]\u001b[A\n",
      " 34%|███▍      | 71310/210001 [00:28<00:46, 2956.28files/s]\u001b[A\n",
      " 34%|███▍      | 71660/210001 [00:28<00:44, 3100.43files/s]\u001b[A\n",
      " 34%|███▍      | 71999/210001 [00:28<00:43, 3181.34files/s]\u001b[A\n",
      " 34%|███▍      | 72328/210001 [00:28<00:43, 3200.64files/s]\u001b[A\n",
      " 35%|███▍      | 72656/210001 [00:28<00:54, 2518.48files/s]\u001b[A\n",
      " 35%|███▍      | 73026/210001 [00:28<00:49, 2785.19files/s]\u001b[A\n",
      " 35%|███▍      | 73333/210001 [00:29<01:03, 2155.03files/s]\u001b[A\n",
      " 35%|███▌      | 73590/210001 [00:29<01:01, 2231.96files/s]\u001b[A\n",
      " 35%|███▌      | 74024/210001 [00:29<00:52, 2612.64files/s]\u001b[A\n",
      " 35%|███▌      | 74375/210001 [00:29<00:47, 2828.92files/s]\u001b[A\n",
      " 36%|███▌      | 74754/210001 [00:29<00:44, 3061.70files/s]\u001b[A\n",
      " 36%|███▌      | 75150/210001 [00:29<00:41, 3284.42files/s]\u001b[A\n",
      " 36%|███▌      | 75506/210001 [00:29<00:50, 2687.42files/s]\u001b[A\n",
      " 36%|███▌      | 75812/210001 [00:30<00:56, 2367.93files/s]\u001b[A\n",
      " 36%|███▋      | 76171/210001 [00:30<00:50, 2635.97files/s]\u001b[A\n",
      " 36%|███▋      | 76550/210001 [00:30<00:46, 2900.47files/s]\u001b[A\n",
      " 37%|███▋      | 76898/210001 [00:30<00:43, 3049.36files/s]\u001b[A\n",
      " 37%|███▋      | 77227/210001 [00:30<00:59, 2225.76files/s]\u001b[A\n",
      " 37%|███▋      | 77528/210001 [00:30<00:54, 2413.51files/s]\u001b[A\n",
      " 37%|███▋      | 77808/210001 [00:30<01:06, 1999.76files/s]\u001b[A\n",
      " 37%|███▋      | 78083/210001 [00:31<01:00, 2176.74files/s]\u001b[A\n",
      " 37%|███▋      | 78417/210001 [00:31<00:54, 2430.01files/s]\u001b[A\n",
      " 37%|███▋      | 78732/210001 [00:31<00:50, 2602.10files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 79018/210001 [00:31<00:52, 2499.60files/s]\u001b[A\n",
      " 38%|███▊      | 79304/210001 [00:31<00:50, 2596.59files/s]\u001b[A\n",
      " 38%|███▊      | 79578/210001 [00:31<00:52, 2478.50files/s]\u001b[A\n",
      " 38%|███▊      | 79912/210001 [00:31<00:48, 2685.10files/s]\u001b[A\n",
      " 38%|███▊      | 80279/210001 [00:31<00:44, 2919.41files/s]\u001b[A\n",
      " 38%|███▊      | 80671/210001 [00:31<00:40, 3160.54files/s]\u001b[A\n",
      " 39%|███▊      | 81036/210001 [00:31<00:39, 3292.10files/s]\u001b[A\n",
      " 39%|███▉      | 81444/210001 [00:32<00:36, 3494.01files/s]\u001b[A\n",
      " 39%|███▉      | 81806/210001 [00:32<00:36, 3494.82files/s]\u001b[A\n",
      " 39%|███▉      | 82165/210001 [00:32<00:36, 3473.84files/s]\u001b[A\n",
      " 39%|███▉      | 82608/210001 [00:32<00:34, 3712.96files/s]\u001b[A\n",
      " 40%|███▉      | 83026/210001 [00:32<00:33, 3839.78files/s]\u001b[A\n",
      " 40%|███▉      | 83420/210001 [00:32<00:32, 3868.64files/s]\u001b[A\n",
      " 40%|███▉      | 83861/210001 [00:32<00:31, 4015.69files/s]\u001b[A\n",
      " 40%|████      | 84268/210001 [00:32<00:31, 3989.99files/s]\u001b[A\n",
      " 40%|████      | 84686/210001 [00:32<00:30, 4044.93files/s]\u001b[A\n",
      " 41%|████      | 85097/210001 [00:32<00:30, 4064.03files/s]\u001b[A\n",
      " 41%|████      | 85544/210001 [00:33<00:29, 4176.34files/s]\u001b[A\n",
      " 41%|████      | 85964/210001 [00:33<00:29, 4169.73files/s]\u001b[A\n",
      " 41%|████      | 86394/210001 [00:33<00:29, 4207.75files/s]\u001b[A\n",
      " 41%|████▏     | 86819/210001 [00:33<00:29, 4217.79files/s]\u001b[A\n",
      " 42%|████▏     | 87242/210001 [00:33<00:32, 3811.72files/s]\u001b[A\n",
      " 42%|████▏     | 87632/210001 [00:33<00:32, 3755.15files/s]\u001b[A\n",
      " 42%|████▏     | 88088/210001 [00:33<00:30, 3963.73files/s]\u001b[A\n",
      " 42%|████▏     | 88515/210001 [00:33<00:30, 4048.95files/s]\u001b[A\n",
      " 42%|████▏     | 88926/210001 [00:33<00:30, 3946.13files/s]\u001b[A\n",
      " 43%|████▎     | 89341/210001 [00:34<00:30, 4004.22files/s]\u001b[A\n",
      " 43%|████▎     | 89745/210001 [00:34<00:30, 3986.28files/s]\u001b[A\n",
      " 43%|████▎     | 90150/210001 [00:34<00:29, 4002.91files/s]\u001b[A\n",
      " 43%|████▎     | 90577/210001 [00:34<00:29, 4079.25files/s]\u001b[A\n",
      " 43%|████▎     | 90992/210001 [00:34<00:29, 4098.16files/s]\u001b[A\n",
      " 44%|████▎     | 91430/210001 [00:34<00:28, 4178.05files/s]\u001b[A\n",
      " 44%|████▎     | 91849/210001 [00:34<00:28, 4135.76files/s]\u001b[A\n",
      " 44%|████▍     | 92264/210001 [00:34<00:29, 4026.73files/s]\u001b[A\n",
      " 44%|████▍     | 92695/210001 [00:34<00:28, 4106.07files/s]\u001b[A\n",
      " 44%|████▍     | 93126/210001 [00:34<00:28, 4164.05files/s]\u001b[A\n",
      " 45%|████▍     | 93544/210001 [00:35<00:28, 4124.74files/s]\u001b[A\n",
      " 45%|████▍     | 93977/210001 [00:35<00:27, 4183.66files/s]\u001b[A\n",
      " 45%|████▍     | 94397/210001 [00:35<00:28, 4078.09files/s]\u001b[A\n",
      " 45%|████▌     | 94836/210001 [00:35<00:27, 4164.43files/s]\u001b[A\n",
      " 45%|████▌     | 95273/210001 [00:35<00:27, 4221.91files/s]\u001b[A\n",
      " 46%|████▌     | 95697/210001 [00:35<00:27, 4212.88files/s]\u001b[A\n",
      " 46%|████▌     | 96134/210001 [00:35<00:26, 4257.61files/s]\u001b[A\n",
      " 46%|████▌     | 96561/210001 [00:35<00:27, 4196.94files/s]\u001b[A\n",
      " 46%|████▌     | 96987/210001 [00:35<00:26, 4213.77files/s]\u001b[A\n",
      " 46%|████▋     | 97409/210001 [00:35<00:26, 4206.55files/s]\u001b[A\n",
      " 47%|████▋     | 97830/210001 [00:36<00:26, 4204.87files/s]\u001b[A\n",
      " 47%|████▋     | 98260/210001 [00:36<00:26, 4231.51files/s]\u001b[A\n",
      " 47%|████▋     | 98709/210001 [00:36<00:25, 4305.41files/s]\u001b[A\n",
      " 47%|████▋     | 99140/210001 [00:36<00:26, 4229.16files/s]\u001b[A\n",
      " 47%|████▋     | 99577/210001 [00:36<00:25, 4268.36files/s]\u001b[A\n",
      " 48%|████▊     | 100005/210001 [00:36<00:26, 4176.16files/s]\u001b[A\n",
      " 48%|████▊     | 100424/210001 [00:36<00:26, 4161.54files/s]\u001b[A\n",
      " 48%|████▊     | 100866/210001 [00:36<00:25, 4235.23files/s]\u001b[A\n",
      " 48%|████▊     | 101291/210001 [00:36<00:25, 4222.49files/s]\u001b[A\n",
      " 48%|████▊     | 101729/210001 [00:36<00:25, 4266.18files/s]\u001b[A\n",
      " 49%|████▊     | 102157/210001 [00:37<00:25, 4193.96files/s]\u001b[A\n",
      " 49%|████▉     | 102600/210001 [00:37<00:25, 4260.17files/s]\u001b[A\n",
      " 49%|████▉     | 103040/210001 [00:37<00:24, 4300.31files/s]\u001b[A\n",
      " 49%|████▉     | 103471/210001 [00:37<00:33, 3224.60files/s]\u001b[A\n",
      " 49%|████▉     | 103903/210001 [00:37<00:30, 3490.06files/s]\u001b[A\n",
      " 50%|████▉     | 104338/210001 [00:37<00:28, 3708.38files/s]\u001b[A\n",
      " 50%|████▉     | 104737/210001 [00:37<00:28, 3727.69files/s]\u001b[A\n",
      " 50%|█████     | 105137/210001 [00:37<00:27, 3805.15files/s]\u001b[A\n",
      " 50%|█████     | 105532/210001 [00:37<00:27, 3827.51files/s]\u001b[A\n",
      " 50%|█████     | 105960/210001 [00:38<00:26, 3949.74files/s]\u001b[A\n",
      " 51%|█████     | 106370/210001 [00:38<00:25, 3992.60files/s]\u001b[A\n",
      " 51%|█████     | 106785/210001 [00:38<00:25, 4037.56files/s]\u001b[A\n",
      " 51%|█████     | 107193/210001 [00:38<00:26, 3819.83files/s]\u001b[A\n",
      " 51%|█████     | 107620/210001 [00:38<00:25, 3943.70files/s]\u001b[A\n",
      " 51%|█████▏    | 108020/210001 [00:38<00:26, 3845.07files/s]\u001b[A\n",
      " 52%|█████▏    | 108409/210001 [00:38<00:26, 3787.95files/s]\u001b[A\n",
      " 52%|█████▏    | 108791/210001 [00:38<00:26, 3786.63files/s]\u001b[A\n",
      " 52%|█████▏    | 109172/210001 [00:38<00:28, 3592.87files/s]\u001b[A\n",
      " 52%|█████▏    | 109598/210001 [00:39<00:26, 3769.83files/s]\u001b[A\n",
      " 52%|█████▏    | 110030/210001 [00:39<00:25, 3918.93files/s]\u001b[A\n",
      " 53%|█████▎    | 110427/210001 [00:39<00:26, 3757.56files/s]\u001b[A\n",
      " 53%|█████▎    | 110808/210001 [00:39<00:37, 2634.14files/s]\u001b[A\n",
      " 53%|█████▎    | 111121/210001 [00:39<00:37, 2656.12files/s]\u001b[A\n",
      " 53%|█████▎    | 111422/210001 [00:39<00:40, 2416.80files/s]\u001b[A\n",
      " 53%|█████▎    | 111772/210001 [00:39<00:36, 2663.96files/s]\u001b[A\n",
      " 53%|█████▎    | 112171/210001 [00:39<00:33, 2957.63files/s]\u001b[A\n",
      " 54%|█████▎    | 112497/210001 [00:40<00:32, 3022.35files/s]\u001b[A\n",
      " 54%|█████▍    | 112880/210001 [00:40<00:30, 3225.54files/s]\u001b[A\n",
      " 54%|█████▍    | 113286/210001 [00:40<00:28, 3435.64files/s]\u001b[A\n",
      " 54%|█████▍    | 113650/210001 [00:40<00:27, 3492.62files/s]\u001b[A\n",
      " 54%|█████▍    | 114012/210001 [00:40<00:28, 3385.46files/s]\u001b[A\n",
      " 54%|█████▍    | 114360/210001 [00:40<00:37, 2542.07files/s]\u001b[A\n",
      " 55%|█████▍    | 114668/210001 [00:40<00:35, 2682.41files/s]\u001b[A\n",
      " 55%|█████▍    | 115020/210001 [00:40<00:32, 2887.24files/s]\u001b[A\n",
      " 55%|█████▍    | 115381/210001 [00:41<00:30, 3070.83files/s]\u001b[A\n",
      " 55%|█████▌    | 115709/210001 [00:41<00:30, 3044.39files/s]\u001b[A\n",
      " 55%|█████▌    | 116105/210001 [00:41<00:28, 3270.06files/s]\u001b[A\n",
      " 55%|█████▌    | 116447/210001 [00:41<00:29, 3206.54files/s]\u001b[A\n",
      " 56%|█████▌    | 116779/210001 [00:41<00:30, 3087.48files/s]\u001b[A\n",
      " 56%|█████▌    | 117097/210001 [00:41<00:30, 3017.27files/s]\u001b[A\n",
      " 56%|█████▌    | 117405/210001 [00:41<00:32, 2888.77files/s]\u001b[A\n",
      " 56%|█████▌    | 117700/210001 [00:41<00:31, 2902.73files/s]\u001b[A\n",
      " 56%|█████▌    | 118002/210001 [00:41<00:31, 2934.71files/s]\u001b[A\n",
      " 56%|█████▋    | 118364/210001 [00:41<00:29, 3111.16files/s]\u001b[A\n",
      " 57%|█████▋    | 118701/210001 [00:42<00:28, 3183.53files/s]\u001b[A\n",
      " 57%|█████▋    | 119024/210001 [00:42<00:29, 3105.25files/s]\u001b[A\n",
      " 57%|█████▋    | 119338/210001 [00:42<00:29, 3105.09files/s]\u001b[A\n",
      " 57%|█████▋    | 119727/210001 [00:42<00:27, 3303.97files/s]\u001b[A\n",
      " 57%|█████▋    | 120063/210001 [00:42<00:35, 2500.92files/s]\u001b[A\n",
      " 57%|█████▋    | 120346/210001 [00:42<00:37, 2366.85files/s]\u001b[A\n",
      " 57%|█████▋    | 120614/210001 [00:42<00:36, 2451.89files/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "decoding with 'cp437' codec failed (KeyboardInterrupt: )",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/RoboND/lib/python3.5/encodings/cp437.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-18629d379856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Get the features and labels from the zip files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muncompress_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'notMNIST_train.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muncompress_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'notMNIST_test.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-18629d379856>\u001b[0m in \u001b[0;36muncompress_features_labels\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Check if the file is a directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mzipf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/RoboND/lib/python3.5/zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, name, mode, pwd)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                 \u001b[0mfname_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0mfname_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cp437\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfname_str\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mzinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: decoding with 'cp437' codec failed (KeyboardInterrupt: )"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with\n",
    "size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/mean_variance.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for your training and test data.\n",
    "\n",
    "Implement Min-Max scaling in the `normalize()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
    "\n",
    "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Min-Max scaling for grayscale image data\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    xmin = 0\n",
    "    xmax = 255\n",
    "    return (a + (image_data - xmin)*(b - a)/(xmax - xmin))\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/weight_biases.png\" style=\"height: 60%;width: 60%; position: relative; right: 10%\">\n",
    "## Problem 2\n",
    "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
    " - `features`\n",
    "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
    " - `labels`\n",
    "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
    " - `keep_prob`\n",
    "  - Placeholder tensor for dropout's keep probability value\n",
    " - `weights`\n",
    "  - List of Variable Tensors with random numbers from a truncated normal distribution for each list index.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
    " - `biases`\n",
    "  - List of Variable Tensors with all zeros for each list index.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count = 784   # 28x288\n",
    "labels_count = 10\n",
    "\n",
    "# Set the hidden layer width. You can try different widths for different layers and experiment.\n",
    "hidden_layer_width = 64\n",
    "\n",
    "# Set the features, labels, and keep_prob tensors\n",
    "features = tf.placeholder(tf.float32, shape = (None, features_count))\n",
    "labels = tf.placeholder(tf.float32, shape = (None, labels_count))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# TODO: Set the list of weights and biases tensors based on number of layers\n",
    "weights = [tf.Variable(tf.truncated_normal([features_count, hidden_layer_width])),\n",
    "          tf.Variable(tf.truncated_normal([hidden_layer_width, labels_count]))]\n",
    "\n",
    "biases = [tf.Variable(tf.zeros([hidden_layer_width])),\n",
    "         tf.Variable(tf.zeros([labels_count]))]\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
    "assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
    "assert all(isinstance(weight, Variable) for weight in weights), 'weights must be a TensorFlow variable'\n",
    "assert all(isinstance(bias, Variable) for bias in biases), 'biases must be a TensorFlow variable'\n",
    "\n",
    "assert features._shape == None or (\\\n",
    "    features._shape.dims[0].value is None and\\\n",
    "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
    "assert labels._shape  == None or (\\\n",
    "    labels._shape.dims[0].value is None and\\\n",
    "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
    "\n",
    "assert features._dtype == tf.float32, 'features must be type float32'\n",
    "assert labels._dtype == tf.float32, 'labels must be type float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 3\n",
    "This problem would help you implement the hidden and output layers of your model. As it was covered in the classroom, you will need the following:\n",
    "\n",
    "- [tf.add](https://www.tensorflow.org/api_docs/python/tf/add) and [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/matmul) to create your hidden and output(logits) layers.\n",
    "- [tf.nn.relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu) for your ReLU activation function.\n",
    "- [tf.nn.dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) for your dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hidden Layers with ReLU Activation and dropouts. \"features\" would be the input to the first layer.\n",
    "hidden_layer_1 = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer_1 = tf.nn.relu(hidden_layer_1)\n",
    "hidden_layer_1 = tf.nn.dropout(hidden_layer_1, keep_prob)\n",
    "\n",
    "# TODO: Output layer\n",
    "logits = tf.add(tf.matmul(hidden_layer_1, weights[1]), biases[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/learn_rate_tune.png\" style=\"height: 60%;width: 60%\">\n",
    "## Problem 4\n",
    "In the previous lab for a single Neural Network, you attempted several different configurations for the hyperparameters given below. Try to first use the same parameters as the previous lab, and then adjust and finetune those values based on your new model if required. \n",
    "\n",
    "You have another hyperparameter to tune now, however. Set the value for keep_probability and observe how it affects your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/5: 100%|██████████| 2850/2850 [00:52<00:00, 54.54batches/s]\n",
      "Epoch  2/5: 100%|██████████| 2850/2850 [00:56<00:00, 50.00batches/s]\n",
      "Epoch  3/5: 100%|██████████| 2850/2850 [00:55<00:00, 51.51batches/s]\n",
      "Epoch  4/5: 100%|██████████| 2850/2850 [00:45<00:00, 62.24batches/s]\n",
      "Epoch  5/5: 100%|██████████| 2850/2850 [00:40<00:00, 71.07batches/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.7512000203132629\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.1\n",
    "keep_probability = 0.5\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels, keep_prob: keep_probability})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict={features: train_features, \n",
    "                                                                     labels: train_labels, keep_prob: keep_probability})\n",
    "                validation_accuracy = session.run(accuracy, feed_dict={features: valid_features, \n",
    "                                                                     labels: valid_labels, keep_prob: 1.0})\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict={features: valid_features, \n",
    "                                                                     labels: valid_labels, keep_prob: 1.0})\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Set the epochs, batch_size, and learning_rate with the best learning parameters you discovered in problem 4.  You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/5: 100%|██████████| 2850/2850 [00:06<00:00, 437.97batches/s]\n",
      "Epoch  2/5: 100%|██████████| 2850/2850 [00:07<00:00, 406.78batches/s]\n",
      "Epoch  3/5: 100%|██████████| 2850/2850 [00:06<00:00, 421.00batches/s]\n",
      "Epoch  4/5: 100%|██████████| 2850/2850 [00:05<00:00, 481.37batches/s]\n",
      "Epoch  5/5: 100%|██████████| 2850/2850 [00:06<00:00, 424.37batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice Job! Test Accuracy is 0.8734999895095825\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set the epochs, batch_size, and learning_rate with the best parameters from problem 4\n",
    "epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels, keep_prob: 1.0})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict={features: test_features, \n",
    "                                                                     labels: test_labels, keep_prob: 1.0})\n",
    "\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
